# =============================================================================
# 模型动作配置: pickup_cube (夹取方块)
# =============================================================================
# 此配置文件从云端下载，定义了完整的数据采集、训练、推理参数
# 存储位置: ~/qyh-robot-system/model_actions/pickup_cube/
# =============================================================================

metadata:
  id: pickup_cube
  name: 夹取方块
  description: 使用右臂和右夹爪抓取桌面上的方块
  version: "1.0.0"
  author: qyh-robot-cloud
  tags:
    - manipulation
    - single-arm
    - gripper
  created_at: "2026-01-12T00:00:00"
  updated_at: "2026-01-12T00:00:00"
  
  # 动作状态：collecting（数据采集中）/ trained（已训练可执行）
  # 注意：此字段由系统根据 model/ 目录下是否有模型文件自动判断
  # 手动设置此字段可以覆盖自动检测（如标记模型质量不佳需要重新训练）
  status: collecting
  
  # 数据统计（由系统自动更新）
  episode_count: 103        # 已采集的轨迹数量
  last_training: null     # 最后一次训练时间
  model_version: null     # 当前模型版本

# =============================================================================
# 数据采集配置
# =============================================================================
collection:
  # 相机配置
  cameras:
    - name: head_rgb
      topic: /head_camera/color/image_raw
      type: rgb
      resize: [224, 224]
      compressed: false
    - name: head_depth
      topic: /head_camera/depth/image_raw
      type: depth
      resize: [224, 224]
      normalize: minmax
      max_depth: 3000
      compressed: false
  
  # 关节配置 - 右臂 7 自由度
  joints:
    topic: /right_arm/joint_states
    names:
      - right_joint1
      - right_joint2
      - right_joint3
      - right_joint4
      - right_joint5
      - right_joint6
      - right_joint7
    include_velocity: false
  
  # 夹爪配置
  grippers:
    - topic: /right/gripper_state
      joint_name: right_gripper_joint
      normalize_range: [0.0, 0.08]
  
  # 时间同步
  sync:
    method: nearest
    tolerance_ms: 50
    target_hz: 30
  
  # 动作类型
  action_type: absolute

# =============================================================================
# 训练配置
# =============================================================================
training:
  batch_size: 128
  num_epochs: 3000
  learning_rate: 4.0e-4
  weight_decay: 1.0e-4
  
  warmup_epochs: 200
  lr_scheduler: cosine
  
  save_interval: 200
  save_best: true
  
  early_stopping: true
  patience: 300
  
  use_amp: true
  grad_clip: 1.0
  
  # ACT 模型配置
  # observation_horizon: 观测历史长度。ACT 原论文使用 1（只看当前帧）
  # 设为 10 会导致每 batch 处理 10 倍图像，训练非常慢！
  observation_horizon: 1
  action_horizon: 20
  action_exec_horizon: 3
  
  hidden_dim: 512
  num_heads: 8
  num_encoder_layers: 4
  num_decoder_layers: 4
  
  latent_dim: 32
  kl_weight: 10.0
  
  vision_backbone: resnet18
  vision_pretrained: true
  freeze_vision: false

# =============================================================================
# 推理配置
# =============================================================================
inference:
  control_frequency: 20.0
  inference_frequency: 10.0
  action_scale: 0.4
  smoothing_alpha: 0.3
  max_joint_velocity: 1.0
  max_joint_delta: 0.05
  gripper_threshold: 0.6

# =============================================================================
# 预处理配置
# =============================================================================
preprocess:
  # 跳过静止片段（可选，用于过滤录制开头/结尾的等待期）
  # 建议保持 false，保留所有数据（包括慢速精细操作）
  skip_static_segments: false
  # 静止检测阈值（rad/帧，30Hz 采样率下）
  # 0.0001：只过滤真正静止的帧（保留 >95% 数据）
  # 原值 0.01 太大，会过滤所有数据
  static_threshold: 0.0001
  # 最小有效片段长度（帧数）
  min_segment_length: 10
  # 检测夹取失败（可选）
  detect_grasp_failure: false
  gripper_close_threshold: 0.3
